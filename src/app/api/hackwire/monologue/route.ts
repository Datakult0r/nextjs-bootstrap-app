import { NextRequest, NextResponse } from 'next/server';
import { MonologueGenerationRequest, MonologueGenerationResponse, APIResponse } from '@/types/hackwire';

// OpenAI configuration
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const OPENAI_BASE_URL = 'https://api.openai.com/v1';

export async function POST(request: NextRequest) {
  try {
    const body: MonologueGenerationRequest = await request.json();
    const { headline, context, image } = body;

    if (!OPENAI_API_KEY) {
      return NextResponse.json({
        success: false,
        error: 'OpenAI API key not configured',
      } as APIResponse<MonologueGenerationResponse>, { status: 500 });
    }

    if (!headline) {
      return NextResponse.json({
        success: false,
        error: 'Headline is required for monologue generation',
      } as APIResponse<MonologueGenerationResponse>, { status: 400 });
    }

    // Construct the prompt for AI monologue generation
    const systemPrompt = `You are a professional news anchor and commentator creating engaging monologues for live streaming overlays. Your task is to create a compelling, informative, and engaging monologue based on the provided news headline.

Guidelines:
- Keep the monologue between 150-300 words
- Use a professional yet engaging tone
- Provide context and analysis, not just facts
- Make it suitable for live streaming audiences
- Include relevant background information when possible
- End with a thought-provoking statement or question
- Avoid controversial political statements
- Focus on the broader implications of the news`;

    const userPrompt = `Create a news monologue for this headline: "${headline}"

${context ? `Additional context: ${context}` : ''}

${image ? `Note: This story includes visual content that will be displayed alongside the monologue.` : ''}

Please create an engaging monologue that would work well for a live news stream overlay.`;

    // Call OpenAI API
    const openaiResponse = await fetch(`${OPENAI_BASE_URL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini', // Using the more cost-effective model
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: userPrompt
          }
        ],
        max_tokens: 500,
        temperature: 0.7,
        presence_penalty: 0.1,
        frequency_penalty: 0.1
      })
    });

    if (!openaiResponse.ok) {
      const errorData = await openaiResponse.json().catch(() => ({}));
      throw new Error(`OpenAI API error: ${openaiResponse.status} ${openaiResponse.statusText} - ${errorData.error?.message || 'Unknown error'}`);
    }

    const openaiData = await openaiResponse.json();

    if (!openaiData.choices || openaiData.choices.length === 0) {
      throw new Error('No monologue generated by OpenAI');
    }

    const monologue = openaiData.choices[0].message.content.trim();

    const response: MonologueGenerationResponse = {
      success: true,
      monologue: monologue,
      usage: openaiData.usage ? {
        prompt_tokens: openaiData.usage.prompt_tokens,
        completion_tokens: openaiData.usage.completion_tokens,
        total_tokens: openaiData.usage.total_tokens
      } : undefined,
      model: openaiData.model
    };

    return NextResponse.json(response);

  } catch (error) {
    console.error('Monologue generation error:', error);
    
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'Failed to generate monologue'
    } as APIResponse<MonologueGenerationResponse>, { status: 500 });
  }
}

// GET method for retrieving monologue templates or examples
export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const type = searchParams.get('type') || 'templates';

    if (type === 'templates') {
      // Return predefined monologue templates
      const templates = [
        {
          id: 'breaking_news',
          name: 'Breaking News',
          template: 'This just in: {headline}. This developing story has significant implications for {context}. We\'ll continue to monitor this situation and bring you updates as they become available.'
        },
        {
          id: 'tech_analysis',
          name: 'Technology Analysis',
          template: 'In the rapidly evolving world of technology, {headline} represents a significant development. This advancement could reshape how we {context}, potentially affecting millions of users worldwide.'
        },
        {
          id: 'business_impact',
          name: 'Business Impact',
          template: 'The business world is buzzing about {headline}. This development could have far-reaching consequences for {context}, potentially influencing market trends and consumer behavior.'
        },
        {
          id: 'general_news',
          name: 'General News',
          template: 'Today\'s headlines bring us {headline}. This story highlights important aspects of {context} that deserve our attention and consideration.'
        }
      ];

      return NextResponse.json({
        success: true,
        templates: templates
      });
    }

    return NextResponse.json({
      success: false,
      error: 'Invalid request type'
    }, { status: 400 });

  } catch (error) {
    console.error('Monologue GET error:', error);
    
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'Failed to process request'
    }, { status: 500 });
  }
}